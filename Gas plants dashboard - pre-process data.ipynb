{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import gspread\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key parameters\n",
    "\n",
    "max_year = 2023\n",
    "min_year = 2021\n",
    "\n",
    "client_secret = \"Desktop/GEM_INFO/client_secret.json\"\n",
    "client_secret_full_path = os.path.expanduser(\"~/\") + client_secret\n",
    "\n",
    "gogpt_dash_file_h1_2023 = 'Global Oil and Gas Plant Tracker (GOGPT) compiled 2023-08-18.xlsx'\n",
    "gogpt_dash_file_h2_2022 = 'Global Gas Plant Tracker (GGPT) 2023-02.xlsx'\n",
    "gogpt_dash_file_h1_2022 = 'Global Gas Plant Tracker 2022-08.xlsx'\n",
    "gogpt_dash_file_h2_2021 = 'Global Gas Plant Tracker (GGPT) 2022-02.xlsx'\n",
    "gogpt_dash_file_h1_2021 = 'Global Gas Plant Tracker 2021-10.xlsx'\n",
    "\n",
    "gogpt_dash_path = os.path.expanduser('/Users/gem-tah/Desktop/GEM_INFO/GEM_WORK/GOGPT/GOGPT-Dashboard/data/pre-2023-08/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogpt_xl_h1_2023 = pd.ExcelFile(gogpt_dash_path + gogpt_dash_file_h1_2023)\n",
    "gogpt_xl_h2_2022 = pd.ExcelFile(gogpt_dash_path + gogpt_dash_file_h2_2022)\n",
    "gogpt_xl_h1_2022 = pd.ExcelFile(gogpt_dash_path + gogpt_dash_file_h1_2022)\n",
    "gogpt_xl_h2_2021 = pd.ExcelFile(gogpt_dash_path + gogpt_dash_file_h2_2021)\n",
    "gogpt_xl_h1_2021 = pd.ExcelFile(gogpt_dash_path + gogpt_dash_file_h1_2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gspread_access_file_read_only(key, title):\n",
    "    \"\"\"\n",
    "    key = Google Sheets unique key in the URL\n",
    "    title = name of the sheet you want to read\n",
    "    \"\"\"\n",
    "    gspread_creds = gspread.oauth(\n",
    "        scopes=[\"https://www.googleapis.com/auth/spreadsheets.readonly\"],\n",
    "        credentials_filename=client_secret_full_path,\n",
    "        # authorized_user_filename=json_token_name,\n",
    "    )\n",
    "    gsheets = gspread_creds.open_by_key(key)\n",
    "    # Access a specific tab\n",
    "    spreadsheet = gsheets.worksheet(title)\n",
    "    # expected_header option provided following: https://github.com/burnash/gspread/issues/1007\n",
    "    df = pd.DataFrame(spreadsheet.get_all_records(expected_headers=[]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def determine_year_month_from_file(gogpt_dash_file):\n",
    "    yyyy_mm = gogpt_dash_file.split('.xlsx')[0].split(' ')[-1]\n",
    "    month_int = int(yyyy_mm.split('-')[1])\n",
    "    year_int = int(yyyy_mm.split('-')[0])\n",
    "\n",
    "    print(f\"year_int: {year_int} month_int: {month_int}\")\n",
    "\n",
    "    return month_int, year_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of countries to choose from (GEM country names)\n",
    "# data in gogpt_status is most complete; example of Albania, which only has cancelled units, nothing else\n",
    "\n",
    "list_of_xls_paths = [gogpt_xl_h1_2023, gogpt_xl_h2_2022, gogpt_xl_h1_2022, gogpt_xl_h2_2021, gogpt_xl_h1_2021]\n",
    "\n",
    "month_h1_2023, year_h1_2023 = determine_year_month_from_file(gogpt_dash_file_h1_2023)\n",
    "month_h2_2022, year_h2_2022 = determine_year_month_from_file(gogpt_dash_file_h2_2022)\n",
    "month_h1_2022, year_h1_2022 = determine_year_month_from_file(gogpt_dash_file_h1_2022)\n",
    "month_h2_2021, year_h2_2021 = determine_year_month_from_file(gogpt_dash_file_h2_2021)\n",
    "month_h1_2021, year_h1_2021 = determine_year_month_from_file(gogpt_dash_file_h1_2021)\n",
    "\n",
    "gogpt_h1_2023 = pd.read_excel(gogpt_xl_h1_2023, sheet_name = 'Gas &amp; Oil Units')\n",
    "gogpt_h1_2023['Version month'] = month_h1_2023\n",
    "gogpt_h1_2023['Version year'] = year_h1_2023\n",
    "\n",
    "gogpt_h2_2022 = pd.read_excel(gogpt_xl_h2_2022, sheet_name = 'Gas Units')\n",
    "gogpt_h2_2022['Version month'] = month_h2_2022\n",
    "gogpt_h2_2022['Version year'] = year_h2_2022\n",
    "\n",
    "gogpt_h1_2022 = pd.read_excel(gogpt_xl_h1_2022, sheet_name = 'Gas plants - data')\n",
    "gogpt_h1_2022['Version month'] = month_h1_2022\n",
    "gogpt_h1_2022['Version year'] = year_h1_2022\n",
    "\n",
    "gogpt_h2_2021 = pd.read_excel(gogpt_xl_h2_2021, sheet_name = 'Gas Units')\n",
    "gogpt_h2_2021['Version month'] = month_h2_2021\n",
    "gogpt_h2_2021['Version year'] = year_h2_2021\n",
    "\n",
    "gogpt_h1_2021 = pd.read_excel(gogpt_xl_h1_2021, sheet_name = 'GGPT - Gas Units')\n",
    "gogpt_h1_2021['Version month'] = month_h1_2021\n",
    "gogpt_h1_2021['Version year'] = year_h1_2021\n",
    "\n",
    "gogpt_country_list = gogpt_h1_2023['Country'].sort_values().unique().tolist()\n",
    "gogpt_country_list = ['all'] + gogpt_country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where capacity or country is na or not found\n",
    "\n",
    "\n",
    "list_of_dfs = [gogpt_h1_2023, gogpt_h2_2022, gogpt_h1_2022, gogpt_h2_2021, gogpt_h1_2021]\n",
    "\n",
    "def clean_status_dfs(df_list):\n",
    "    list_of_dfs_clean = []\n",
    "    for df in list_of_dfs:\n",
    "        print(df.shape)\n",
    "        # TODO test to see if this is removing more than we want\n",
    "        df = df.rename(columns={'Capacity elec. (MW)': 'Capacity (MW)'})\n",
    "        # df = df.dropna(subset=['Capacity (MW)', 'Country']) # capacity null items in gogpt_h1_2022 \n",
    "        df = df.replace({'Capacity (MW)':'not found'}, 0)\n",
    "        # df = df.drop(df[df['Capacity (MW)'] == 'not found'].index) # hits all but gogpt_h1_2022\n",
    "        print(df.shape)\n",
    "        list_of_dfs_clean.append(df)\n",
    "    return list_of_dfs_clean\n",
    "\n",
    "gogpt_h1_2023, gogpt_h2_2022, gogpt_h1_2022, gogpt_h2_2021, gogpt_h1_2021 = clean_status_dfs(list_of_dfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map (upper left)\n",
    "- pivot capacity by country in gogpt_h1_2023 to get map tab for gogpt input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pivot on capacities from country\n",
    "# gogpt_h1_2023 is df, so pivot sum on column ['Capacity MW'] for all ['Country'] \n",
    "# remove unnecessary columns\n",
    "# then groupby country and sum\n",
    "\n",
    "\n",
    "gogpt_map = gogpt_h1_2023[['Country', 'Capacity (MW)', 'Status']].copy() \n",
    "print(gogpt_map.shape[0])\n",
    "# filter by operating status then sum capacities by country\n",
    "# TODO: wasn't filtering for operating that before so check GCPT! \n",
    "gogpt_map = gogpt_map[gogpt_map['Status'] == 'operating'] \n",
    "print(gogpt_map.shape[0])\n",
    "\n",
    "gogpt_map['Capacity (MW)'] = pd.to_numeric(gogpt_map['Capacity (MW)'])\n",
    "\n",
    "\n",
    "# gogpt_map = gogpt_map.groupby(['Country']).sum().reset_index()\n",
    "# gogpt_map = gogogpt_map = gogpt_map.groupby(['Country']).sum().reset_index()\n",
    "gogpt_map = gogpt_map.groupby(['Country'])[['Capacity (MW)']].sum().reset_index()\n",
    "\n",
    "# gogpt_map = gogpt_map.groupby(by=\"Country\")[\"Capacity (MW)\"].sum()\n",
    "# Convert \"to int\"\n",
    "gogpt_map = gogpt_map.astype({'Capacity (MW)':'int'})\n",
    "# rslt_df_op[rslt_df_op['Country'] == 'Algeria'] # exact\n",
    "# rslt_df_op[rslt_df_op['Country'] == 'Brazil'] # exact\n",
    "# rslt_df_op[rslt_df_op['Country'] == 'China'] # exact\n",
    "# print(rslt_df_op['Capacity (MW)'].sum()) # slightly off compared to pivot probably float v int known issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_code_df():\n",
    "\n",
    "    gem_naming_convention_key = '1mtlwSJfWy1gbIwXVgpP3d6CcUEWo2OM0IvPD6yztGXI'\n",
    "\n",
    "    # gspread way\n",
    "    country_codes = gspread_access_file_read_only(gem_naming_convention_key, 'Countries')\n",
    "\n",
    "    # clean up the codes to remove non-printing characters from wikipedia\n",
    "    for col in country_codes.columns:\n",
    "        if country_codes[col].dtype == object:\n",
    "            country_codes[col] = country_codes[col].str.replace('\\xa0', '', regex=False)\n",
    "\n",
    "    # get rid of parenthetical footnotes at end of names & whitespace\n",
    "    country_codes['ISO 3166 Country Name'] = country_codes['ISO 3166 Country Name'].str.split('[').str[0].str.strip()\n",
    "\n",
    "    return country_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_country_name_conversions_dict():\n",
    "    \"\"\"\n",
    "    Creates a dictionary for converting GEM standard country names to ISO 3166 versions.\n",
    "    \n",
    "    This downloads the GEM standard names file from Google Sheets using pygsheets,\n",
    "    then pares down the df to only those in which GEM uses a different name than ISO 3166.\n",
    "\n",
    "    Then it creates a dictionary, which can be used for converting from GEM to ISO.\n",
    "    \n",
    "    This is needed because Plotly's choropleth function uses ISO names for getting the outline for each country.\n",
    "    \"\"\"\n",
    "    \n",
    "    standard_country_names_key = '1mtlwSJfWy1gbIwXVgpP3d6CcUEWo2OM0IvPD6yztGXI'\n",
    "\n",
    "    # gspread way\n",
    "    df = gspread_access_file_read_only(standard_country_names_key, 'Countries')\n",
    "    # keep only those with a mismatch\n",
    "    name_diffs = df.copy()\n",
    "    name_diffs = name_diffs[name_diffs['GEM name same as ISO 3166?']=='FALSE']\n",
    "    # exclude those not in ISO\n",
    "    name_diffs = name_diffs[name_diffs['ISO 3166 Country Name']!='NOT LISTED']\n",
    "    name_diffs_dict = name_diffs.set_index('GEM Standard Country Name')['ISO 3166 Country Name'].to_dict()   \n",
    "    \n",
    "    return name_diffs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add any missing countries, to make sure that all countries in gogpt_country_list are in gogpt_map\n",
    "missing_countries = [x for x in gogpt_country_list if x not in gogpt_map['Country'].tolist()]\n",
    "if len(missing_countries) > 0:\n",
    "    print(f\"These countries were missing: {missing_countries}\")\n",
    "    missing_df = pd.DataFrame.from_dict({\n",
    "            'Country': missing_countries, \n",
    "            'Capacity (MW)': [float(0)]*len(missing_countries)\n",
    "        }, orient='columns')\n",
    "    gogpt_map = pd.concat([gogpt_map, missing_df], sort=False)\n",
    "\n",
    "# change GEM country names to ISO 3166\n",
    "name_diffs_dict = create_country_name_conversions_dict()\n",
    "gogpt_map['ISO 3166 Country Name'] = gogpt_map['Country'].replace(name_diffs_dict)\n",
    "\n",
    "# Note: Kosovo isn't recognized in ISO 3166, so can't be shown on Plotly map on its own. \n",
    "# We could combine it with Serbia for display--but then our data in the dashboard wouldn't be the same as in our spreadsheets & other maps.\n",
    "# Wikipedia said Kosovo declared independence from Serbia in 2008; it is only partially recognized.\n",
    "\n",
    "# show countries in gogpt_map not in gogpt_country_list:\n",
    "extraneous_countries = [x for x in gogpt_map['Country'].tolist() if x not in gogpt_country_list]\n",
    "if len(extraneous_countries) > 0:\n",
    "    print(f\"Extraneous countries to be removed: {extraneous_countries}\")\n",
    "\n",
    "# keep only countries that are in gogpt_country_list\n",
    "gogpt_map = gogpt_map[gogpt_map['Country'].isin(gogpt_country_list)]\n",
    "\n",
    "# merge in ISO country codes (needed by Plotly)\n",
    "country_codes = create_country_code_df()\n",
    "gogpt_map = pd.merge(\n",
    "    country_codes[['ISO 3166 Country Name', 'Country ISO 3166-1 alpha-3']],\n",
    "    gogpt_map,\n",
    "    on='ISO 3166 Country Name', \n",
    "    how='outer'\n",
    ")\n",
    "gogpt_map = gogpt_map.rename(columns={'Country ISO 3166-1 alpha-3': 'iso_alpha'})\n",
    "\n",
    "# exclude those with no value for iso_alpha\n",
    "# This excludes notes within the ISO dataset, e.g., \"Akrotiri and Dhekelia – See United Kingdom, The.\"\n",
    "# Unfortunately, this also excludes Kosovo from gogpt\n",
    "gogpt_map = gogpt_map[gogpt_map['iso_alpha'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if capacity is 0, instead use 1, to avoid zero capacity leading to -inf log value\n",
    "# similar approach is used in numpy log1p\n",
    "# https://numpy.org/doc/stable/reference/generated/numpy.log1p.html\n",
    "gogpt_map['capacity log10 + 1'] = np.log10(gogpt_map['Capacity (MW)'].replace(float(0), float(1)))\n",
    "\n",
    "# create hover text\n",
    "# (note: variable hover_text below is a Pandas Series)\n",
    "hover_text = gogpt_map['Country'] + ': '\n",
    "hover_text = hover_text + gogpt_map['Capacity (MW)'].map('{:,.0f}'.format) + ' MW'\n",
    "# hide extra bit, e.g. 'trace 0'; based on https://plotly.com/python/reference/#scatter-hovertemplate\n",
    "hover_text = hover_text + '<extra></extra>'\n",
    "gogpt_map['hover_text'] = hover_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogpt_map  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status graph\n",
    "- from orig get status column, and country column, and capacity column groupby country and status, removing retired and cancelled\n",
    "- do this for 2020, 2021, 2022, 2023 datasets and create column for which year it is then combine all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs_status = [gogpt_h1_2023, gogpt_h2_2022, gogpt_h1_2022, gogpt_h2_2021, gogpt_h1_2021]\n",
    "accepted_statuses = ['announced', 'construction', 'mothballed', 'operating', 'pre-construction', 'shelved']\n",
    "\n",
    "\n",
    "def filter_by_accepted_status(list_of_dfs):\n",
    "    filtered_status_dfs= []\n",
    "    for df in list_of_dfs:\n",
    "        df_status = df[['Country', 'Capacity (MW)', 'Status', 'Version month', 'Version year', 'GEM unit ID']].copy() \n",
    "        # before = df_status.shape[0]\n",
    "        # print(f'before: {df_status.shape[0]}')\n",
    "        df_status['Status'] = df_status['Status'].replace({'proposed': 'pre-construction'})\n",
    "        df_status = df_status[df_status['Status'].isin(accepted_statuses)]\n",
    "        # after = df_status.shape[0]\n",
    "        # print(f'after: {df_status.shape[0]}')\n",
    "        # if before - after == unwanted:\n",
    "        #     print(\"all accounted for\")\n",
    "        # else:\n",
    "        #     print(\"could be a slight problem, numbers don't line up\")\n",
    "\n",
    "        version_month = df_status['Version month'].values[0]\n",
    "        version_year = df_status['Version year'].values[0]\n",
    "        df_status = df_status[['Country', 'Capacity (MW)', 'Status']].copy()\n",
    "        \n",
    "        table = pd.pivot_table(df_status, values='Capacity (MW)', index=['Country','Status'], aggfunc='sum', fill_value=0).reset_index()\n",
    "        print(table[table['Country'] == 'China'])\n",
    "        # TODO remove below groupby\n",
    "        # df_status_mw = df_status_mw.groupby(['Country','Status', 'Capacity (MW)']).sum(['Capacity (MW)']).reset_index()\n",
    "        # df_status_mw = df_status_mw.groupby(['Country','Status']).sum(['Capacity (MW)']).reset_index()\n",
    "\n",
    "        # df_status = df_status.rename(columns={\n",
    "        # 'Status': version_year, \n",
    "        # })\n",
    "        if version_month >= 6:\n",
    "            xaxis_version_year = version_year + .5\n",
    "        else:\n",
    "            xaxis_version_year = version_year\n",
    "        status_column = f'{xaxis_version_year}'\n",
    "        table = table.rename(columns={\n",
    "            'Status': status_column, \n",
    "            })\n",
    "        filtered_status_dfs.append(table)\n",
    "\n",
    "    return filtered_status_dfs\n",
    "\n",
    "status_gogpt_h1_2023, status_gogpt_h2_2022, status_gogpt_h1_2022, status_gogpt_h2_2021, status_gogpt_h1_2021 = filter_by_accepted_status(list_of_dfs_status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests against excel\n",
    "status_gogpt_h1_2023[status_gogpt_h1_2023['Country'] == 'Brazil']\n",
    "status_gogpt_h1_2023[status_gogpt_h1_2023['Country'] == 'China']\n",
    "status_gogpt_h1_2023[status_gogpt_h1_2023['Country'] == 'Algeria']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test that the appropriate rows were removed via the status function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_not_accepted_status(list_of_dfs):\n",
    "    re_filtered_status_dfs = []\n",
    "    for df in list_of_dfs:\n",
    "        df_status = df[['Country', 'Capacity (MW)', 'Status', 'Version month', 'Version year', 'GEM unit ID']].copy() \n",
    "\n",
    "        df_status['Status'] = df_status['Status'].replace({'proposed': 'pre-construction'})\n",
    "        df_status = df_status[~df_status['Status'].isin(accepted_statuses)]\n",
    "        # sum the capacity for all plants that have a bad status to see how much we'll miss in case things don't line up\n",
    "        version_month = df_status['Version month'].values[0]\n",
    "        version_year = df_status['Version year'].values[0]\n",
    "        df_status = df_status[['Country', 'Capacity (MW)', 'Status']].copy()\n",
    "        # df_status = df_status.groupby(['Country','Status', 'Capacity (MW)']).sum(['Capacity (MW)']).reset_index()\n",
    "        \n",
    "        df_status_mw = df_status.groupby(['Country','Status','Capacity (MW)']).sum(['Capacity (MW)']).reset_index()\n",
    "        df_status_mw = df_status_mw.groupby(['Country','Status']).sum(['Capacity (MW)']).reset_index()\n",
    "        \n",
    "        if version_month >= 6:\n",
    "            xaxis_version_year = version_year + .5\n",
    "        else:\n",
    "            xaxis_version_year = version_year\n",
    "        status_column = f'{xaxis_version_year}'\n",
    "        df_status_mw = df_status_mw.rename(columns={\n",
    "            'Status': status_column, \n",
    "            })\n",
    "        # df_status['xaxis'] = xaxis_version_year\n",
    "        re_filtered_status_dfs.append(df_status_mw)\n",
    "\n",
    "    return re_filtered_status_dfs\n",
    "\n",
    "restatus_gogpt_h1_2023, restatus_gogpt_h2_2022, restatus_gogpt_h1_2022, restatus_gogpt_h2_2021, restatus_gogpt_h1_2021 = filter_by_not_accepted_status(list_of_dfs_status)\n",
    "\n",
    "\n",
    "restatus_gogpt_h1_2023\n",
    "print(restatus_gogpt_h1_2023[restatus_gogpt_h1_2023['Country'] == 'Brazil'])\n",
    "#    Country     2023.5  Capacity (MW)\n",
    "# 16  Brazil  cancelled          260.0\n",
    "# 17  Brazil  cancelled         1768.0\n",
    "restatus_gogpt_h1_2023[restatus_gogpt_h1_2023['Country'] == 'Brazil']\n",
    "restatus_gogpt_h1_2023\n",
    "countries_unique_check = restatus_gogpt_h1_2023['Country'].unique()\n",
    "print(sorted(countries_unique_check))\n",
    "print(len(countries_unique_check))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all status dfs\n",
    "\n",
    "\n",
    "gogpt_status_merged = pd.merge(\n",
    "    status_gogpt_h1_2023,\n",
    "    status_gogpt_h2_2022,\n",
    "    on=['Country', 'Capacity (MW)'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "gogpt_status_merged = pd.merge(\n",
    "    gogpt_status_merged,\n",
    "    status_gogpt_h1_2022,\n",
    "    on=['Country', 'Capacity (MW)'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "gogpt_status_merged = pd.merge(\n",
    "    gogpt_status_merged,\n",
    "    status_gogpt_h2_2021,\n",
    "    on=['Country', 'Capacity (MW)'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "gogpt_status_merged = pd.merge(\n",
    "    gogpt_status_merged,\n",
    "    status_gogpt_h1_2021,\n",
    "    on=['Country', 'Capacity (MW)'],\n",
    "    how='outer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_clean_data(df):\n",
    "    for col in df.columns:\n",
    "        if col not in ['Country', 'Capacity (MW)', 'xaxis']:\n",
    "            # make the text lowercase\n",
    "            print(f\"Cleaning col {col}\")\n",
    "            df[col] = df[col].str.lower()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_status(df):\n",
    "    \"\"\"\n",
    "    convert column 'Status' to categorical\n",
    "    https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html\n",
    "    \"\"\"\n",
    "    \n",
    "    status_order = [\n",
    "        'operating',\n",
    "        'mothballed',\n",
    "        'announced',\n",
    "        'pre-construction',\n",
    "        'construction',\n",
    "        # 'retired',\n",
    "        'shelved',\n",
    "        # 'cancelled',\n",
    "    ]\n",
    "    df['Status'] = df['Status'].astype(\n",
    "        CategoricalDtype(status_order, ordered=False)\n",
    "    )    \n",
    "    df = df.sort_values(by=['Country', 'Status', 'Year'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_test_capacity(df, df_init):\n",
    "    \"\"\"Runs at end of status_condense, to check that there was no change in the data.\n",
    "    (Comparing version after condensing the data as it was before condensing the data.)\n",
    "    \n",
    "    There are entries with status NaN in the version of the data before condensing,\n",
    "    because the table prior to that step has a row for each unit, and columns for each year.\n",
    "    (Other distinguishing features for each unit aren't included in this table.)\n",
    "    \n",
    "    If there is no data for a unit for some of the years covered, then we have status NaN for those years.\n",
    "    (Example: It was proposed only in 2018, then the years 2014-2017 have status NaN.)\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.reset_index()\n",
    "        \n",
    "    all_statuses = []\n",
    "\n",
    "    for year in ['2021.5', '2022', '2022.5', '2023', '2023.5']:\n",
    "        all_statuses += df_init[year].tolist() \n",
    "\n",
    "    all_statuses = list(set(all_statuses))\n",
    "\n",
    "    for sel_status in all_statuses:\n",
    "        print(f\"Testing capacities for {sel_status}\")\n",
    "        for sel_year in ['2021.5', '2022', '2022.5', '2023', '2023.5']:\n",
    "            sel_init = df_init[df_init[sel_year]==sel_status]\n",
    "            sel_init_sum = sel_init['Capacity (MW)'].sum()\n",
    "\n",
    "            # handle two different formats for df\n",
    "            if 'Status' in df.columns:\n",
    "                sel = df[(df['Year']==sel_year) & (df['Status']==sel_status)]\n",
    "                sel_sum = sel['Capacity (MW)'].sum()\n",
    "                \n",
    "            else:\n",
    "                sel = df[df[sel_year]==sel_status]\n",
    "                sel_sum = sel['Capacity (MW)'].sum()\n",
    "\n",
    "            # compare values\n",
    "            abs_diff = abs(sel_sum - sel_init_sum)\n",
    "            if abs_diff <= 1e-7:\n",
    "                pass\n",
    "\n",
    "            elif abs_diff > 1e-7:\n",
    "                print(\"Error!\" + f\" Capacity difference for {sel_year} & {sel_status}.\")\n",
    "                print(f\"Initial value: {sel_init_sum}\")\n",
    "                print(f\"Current value: {sel_sum}\")\n",
    "            else:\n",
    "                print(\"Unexpected case\")\n",
    "    \n",
    "    # no return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_fill_in_missing(df):\n",
    "    \"\"\"\n",
    "    For each country, for each status, fill in zero value if it is missing.\n",
    "    \"\"\"\n",
    "    # year_range = range(df['Year'].min(), df['Year'].max() + 1)\n",
    "    year_range = ['2021.5', '2022', '2022.5', '2023', '2023.5']\n",
    "    statuses = df['Status'].dropna().unique().tolist()\n",
    "    for country in df['Country'].unique().tolist():\n",
    "        for status in statuses:\n",
    "            for year in year_range:\n",
    "                df_sel = df[(df['Year']==year) & (df['Country']==country) & (df['Status']==status)]\n",
    "                if len(df_sel) == 0:\n",
    "                    # there is a missing value; fill it in\n",
    "                    # print(f\"To fill in missing value for {country}, {year}, {status}\") # for db\n",
    "                    # values in dict below must be lists, to avoid error:\n",
    "                    # \"ValueError: If using all scalar values, you must pass an index\"\n",
    "                    new_df = pd.DataFrame.from_dict({\n",
    "                                'Country': [country],\n",
    "                                'Year': [year],\n",
    "                                'Status': [status],\n",
    "                                'Capacity (MW)': [float(0)],\n",
    "                            }, orient='columns')\n",
    "                    df = pd.concat([df, new_df], sort=False)\n",
    "\n",
    "    df = df.sort_values(by=['Country', 'Year', 'Status'])\n",
    "                    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_calculate_global_totals(df):    \n",
    "    # gogpt_status_all = df.groupby(['Year', 'Status'])[['Capacity (MW)']].sum().reset_index()\n",
    "    gogpt_status_all = pd.pivot_table(df, values='Capacity (MW)', index=['Year','Status'], aggfunc='sum', fill_value=0).reset_index()\n",
    "    gogpt_status_all.insert(0, 'Country', 'all')\n",
    "    gogpt_status_all = sort_status(gogpt_status_all)\n",
    "    \n",
    "    df = pd.concat([gogpt_status_all, df], sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_condense(df_arg):\n",
    "    \"\"\"\n",
    "    There are sometimes duplicates, for example if two units in a plant have the exact same capacity and history.\n",
    "    So before setting the index to Country & Capacity, need to get rid of duplicates.\n",
    "    \"\"\"\n",
    "    df = df_arg.copy()\n",
    "    df_init = df_arg.copy()  # for test\n",
    "    \n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    df = df.set_index(['Country', 'Capacity (MW)'])\n",
    "    df = df.stack().reset_index()\n",
    "        \n",
    "    df = df.rename(columns={'level_2': 'Year', 0: 'Status'})\n",
    "    \n",
    "    df = df.groupby(['Country', 'Year', 'Status'])[['Capacity (MW)']].sum().reset_index()\n",
    "    df = sort_status(df)\n",
    "\n",
    "    # print(df.columns) # for db\n",
    "    status_test_capacity(df, df_init)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_statuses(gogpt_status_uncondensed_merged):\n",
    "    accepted_statuses = ['announced', 'construction', 'mothballed', 'operating', 'pre-construction', 'shelved']\n",
    "    for col in ['2021.5', '2022', '2022.5', '2023', '2023.5']:\n",
    "        ser = gogpt_status_uncondensed_merged[col].dropna()\n",
    "        unaccepted = ser[~ser.isin(accepted_statuses)]\n",
    "        if len(unaccepted) > 0:\n",
    "            print(f\"Found unaccepted statuses; len(ser): {len(ser)}\")\n",
    "            print(unaccepted.value_counts())\n",
    "    # no return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gogpt_status_uncondensed_merged = status_clean_data(gogpt_status_merged)\n",
    "test_statuses(gogpt_status_uncondensed_merged)\n",
    "\n",
    "gogpt_status = status_condense(gogpt_status_uncondensed_merged)\n",
    "gogpt_status = status_fill_in_missing(gogpt_status)\n",
    "gogpt_status = status_calculate_global_totals(gogpt_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing the merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogpt_status_uncondensed_merged.head()\n",
    "gogpt_status_uncondensed_merged.sample()\n",
    "\n",
    "list_of_dfs = [gogpt_status]\n",
    "country = 'China'\n",
    "cap = 60.0\n",
    "for df in list_of_dfs:\n",
    "    test_df = df[(df['Country'] == country)]\n",
    "    print(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age & Technology (lower left)\n",
    "- For bar chart of capacity by age & type\n",
    "- From the sheet 'Plant type and age'\n",
    "- same as coal, first make the age variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create age variable\n",
    "gogpt_age = gogpt_h1_2023[['Country', 'Capacity (MW)', 'Start year', 'Status', 'Technology']].copy()\n",
    "\n",
    "# TODO filter for operating - double check GCPT too\n",
    "print(gogpt_age.shape[0])\n",
    "gogpt_age = gogpt_age[gogpt_age['Status'] == 'operating'] \n",
    "print(gogpt_age.shape[0])\n",
    "\n",
    "gogpt_age['Capacity (MW)'] = pd.to_numeric(gogpt_age['Capacity (MW)'])\n",
    "\n",
    "gogpt_age = gogpt_age.dropna(subset= ['Start year']) #, 'Technology']\n",
    "print(gogpt_age.shape[0])\n",
    "\n",
    "gogpt_age = gogpt_age.drop(gogpt_age[gogpt_age['Start year'] == 'not found'].index) \n",
    "print(gogpt_age.shape[0])\n",
    "\n",
    "gogpt_age['Technology'] = gogpt_age['Technology'].fillna('not found')\n",
    "\n",
    "plant_ages = []\n",
    "for value in gogpt_age['Start year']:\n",
    "    if '-' in str(value):\n",
    "        first_yr = int(value.split('-')[0].strip())\n",
    "        sec_yr = int(value.split('-')[1].strip())\n",
    "        if sec_yr < first_yr:\n",
    "            print(f\"whooops {sec_yr} is less than {first_yr}\")\n",
    "            plant_age = 'not valid'\n",
    "            plant_ages.append(plant_age)\n",
    "        elif first_yr >= max_year:\n",
    "            plant_age = 0\n",
    "            plant_ages.append(plant_age)\n",
    "        else:\n",
    "            plant_age = max_year - int(first_yr)\n",
    "            plant_ages.append(plant_age)\n",
    "\n",
    "    elif value >= max_year:\n",
    "        plant_age = 0\n",
    "        plant_ages.append(plant_age)\n",
    "    else:\n",
    "       plant_age = max_year - int(value)\n",
    "       # TODO check if no start year is caught\n",
    "       plant_ages.append(plant_age)\n",
    "\n",
    "\n",
    "if len(plant_ages) != gogpt_age.shape[0]:\n",
    "    print(\"Something went wrong with logic, missing a plant age for a row.\")\n",
    "else:\n",
    "    gogpt_age['Plant Age'] = plant_ages\n",
    "        \n",
    "        \n",
    "gogpt_age['Capacity (MW)'] = pd.to_numeric(gogpt_age['Capacity (MW)'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_read_and_clean(gogpt_age):\n",
    "    # rename technology to be human friendly \n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'GT', 'Gas Turbine'\n",
    "    )\n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'ST', 'Steam Turbine'\n",
    "    )\n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'CC', 'Combined Cycle'\n",
    "    )\n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'ICCC', 'Internal Combustion Combined Cycle'\n",
    "    )   \n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'ISCC', 'Integrated Solar Combined Cycle'\n",
    "    ) \n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'IC', 'Internal Combustion'\n",
    "    ) \n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'AFC', 'Allam-Fetvedt Cycle'\n",
    "    ) \n",
    "\n",
    "    # change not found technology to unknown\n",
    "\n",
    "    gogpt_age['Technology'] = gogpt_age['Technology'].replace(\n",
    "        'not found', 'Unknown'\n",
    "    ) \n",
    "\n",
    "    return gogpt_age\n",
    "\n",
    "gogpt_age = age_read_and_clean(gogpt_age)\n",
    "gogpt_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing out new way to group\n",
    "def age_condense_data(df):\n",
    "    print(len(df))\n",
    "    # to fix for future warning that dtype is float64 because nan if not set and then incompatible\n",
    "    # df[\"Decade\"] = \"\"\n",
    "    # bin by decade\n",
    "    for row in df.index:\n",
    "        age = df.at[row, 'Plant Age']\n",
    "        if age < 10:\n",
    "            df.at[row, 'Decade'] = '0-9 years'\n",
    "        elif age >= 10 and age < 20:\n",
    "            df.at[row, 'Decade'] = '10-19 years'\n",
    "        elif age >= 20 and age < 30:\n",
    "            df.at[row, 'Decade'] = '20-29 years'\n",
    "        elif age >= 30 and age < 40:\n",
    "            df.at[row, 'Decade'] = '30-39 years'\n",
    "        elif age >= 40 and age < 50:\n",
    "            df.at[row, 'Decade'] = '40-49 years'\n",
    "        elif age >= 50:\n",
    "            df.at[row, 'Decade'] = '50+ years'\n",
    "        else:\n",
    "            print(\"Error!\" + f\" Issue with age for row {row}: {age}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "gogpt_age = age_condense_data(gogpt_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_calculate_global_totals(df):\n",
    "    \n",
    "    gogpt_age_all = pd.pivot_table(df, values='Capacity (MW)', index=['Decade', 'Technology'], aggfunc='sum', fill_value=0).reset_index()\n",
    "    gogpt_age_all.insert(0, 'Country', 'all')\n",
    "\n",
    "    df = pd.concat([gogpt_age_all, df], sort=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "gogpt_age = age_calculate_global_totals(gogpt_age)\n",
    "gogpt_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sum_age(df):\n",
    "    table_age = pd.pivot_table(df, values='Capacity (MW)', index=['Decade', 'Technology', 'Country'], aggfunc='sum', fill_value=0).reset_index()\n",
    "\n",
    "    # unstack, then fill in zeros\n",
    "    # # TODO understand unstack - pivot a level of the df's indexes if not multi index then returns a series \n",
    "    # df = df.set_index(['Country', 'Decade', 'Technology']).unstack()\n",
    "    # df = df.droplevel(0, axis=1)\n",
    "    table_age = table_age.set_index(['Country', 'Decade', 'Technology']).unstack()\n",
    "    table_age = table_age.droplevel(0, axis=1)\n",
    "\n",
    "    for col in table_age.columns:\n",
    "        table_age[col] = table_age[col].fillna(0)\n",
    "\n",
    "    # it names the index\n",
    "    table_age = table_age.reset_index()\n",
    "    table_age.columns.name = ''\n",
    "    \n",
    "    \n",
    "\n",
    "    return table_age\n",
    "\n",
    "gogpt_age = sum_age(gogpt_age)\n",
    "gogpt_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test against tracker data without doing long sumif statement to create decades\n",
    "test = gogpt_age[(gogpt_age['Country']=='all') & (gogpt_age['Decade']=='0-9 years')]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def age_fill_in_missing_decades(df):\n",
    "    decade_list = [\n",
    "        '0-9 years',\n",
    "        '10-19 years',\n",
    "        '20-29 years',\n",
    "        '30-39 years',\n",
    "        '40-49 years',\n",
    "        '50+ years',\n",
    "    ]\n",
    "    for country_sel in gogpt_country_list:\n",
    "        for decade_sel in decade_list:\n",
    "            # select where the country and decade match within the existing df\n",
    "            df_sel = df[(df['Country']==country_sel) & (df['Decade']==decade_sel)]\n",
    "            # print(df_sel)\n",
    "            # print(len(df_sel))\n",
    "            if len(df_sel) == 0:\n",
    "                print(f'length is zero for this decade and country: {country_sel} {decade_sel}')\n",
    "                new_df = pd.DataFrame.from_dict({\n",
    "                        'Country': country_sel,\n",
    "                        'Decade': decade_sel,\n",
    "                        'Gas Turbine': [float(0)],\n",
    "                        'Steam Turbine': [float(0)],\n",
    "                        'Combined Cycle': [float(0)],\n",
    "                        'Internal Combustion Combined Cycle': [float(0)],\n",
    "                        'Integrated Solar Combined Cycle': [float(0)],\n",
    "                        # 'Ultra-Integrated Solar Combined Cycle': [float(0)],\n",
    "                        'Allam-Fetvedt Cycle': [float(0)],\n",
    "                        'Internal Combustion': [float(0)],\n",
    "                        'Unknown': [float(0)],\n",
    "                    }, orient='columns')\n",
    "                df = pd.concat([df, new_df], sort=False)\n",
    "\n",
    "            elif len(df_sel) == 1:\n",
    "\n",
    "                pass\n",
    "\n",
    "            elif len(df_sel) > 1:\n",
    "                print(\"Error!\"+ f'{country_sel} and {decade_sel}')\n",
    "\n",
    "            else:\n",
    "                print(\"Error! (of another kind)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "gogpt_age = age_fill_in_missing_decades(gogpt_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additions \n",
    "- data for bar chart additions (lower-right)\n",
    "- sheet '2000-2022' (for example)\n",
    "- need country year capacity status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create add df \n",
    "gogpt_add = gogpt_h1_2023[['Country', 'Capacity (MW)', 'Start year', 'Status']].copy()\n",
    "print(gogpt_add.shape)\n",
    "gogpt_add = gogpt_add.dropna(subset=['Start year'])\n",
    "gogpt_add = gogpt_add.drop(gogpt_add[gogpt_add['Start year'] == 'not found'].index) \n",
    "print(gogpt_add.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# handle all year ranges (needed for older data but this graph doesn't use older data)\n",
    "for row in gogpt_add.index:\n",
    "    year = gogpt_add.at[row, 'Start year']\n",
    "    if '-' in str(year):\n",
    "        first_yr = int(year.split('-')[0].strip())\n",
    "        gogpt_add.at[row, 'Start year'] = first_yr\n",
    "    elif ',' in str(year):\n",
    "        first_yr = int(year.split(',')[0].strip())\n",
    "        gogpt_add.at[row, 'Start year'] = first_yr\n",
    "    elif ';'in str(year):\n",
    "        first_yr = int(year.split(';')[0].strip())\n",
    "        gogpt_add.at[row, 'Start year'] = first_yr\n",
    "\n",
    "\n",
    "# replace 'before 1992' with 1992\n",
    "gogpt_add = gogpt_add.drop(gogpt_add[gogpt_add['Start year'] == 'before 1992'].index)\n",
    "\n",
    "# remove any years before 2000 NOTE: this is why some sums are different from excel \n",
    "gogpt_add = gogpt_add[gogpt_add['Start year'] >= 2000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that it did it's thing\n",
    "for value in gogpt_add['Start year']:\n",
    "    if '-' in str(value):\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we just want to drop any rows that don't have status == operating\n",
    "gogpt_add = gogpt_add[gogpt_add['Status']=='operating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogpt_add = gogpt_add.groupby(['Country','Start year', 'Status']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_unstack(df):\n",
    "    df = df.set_index(['Country', 'Start year', 'Status'])\n",
    "    # rearranges / pivots data of df\n",
    "    # df = df.unstack(-1)\n",
    "    df = df.unstack()\n",
    "\n",
    "    # removes first row since: 1 or ‘columns’: remove level(s) in row.\n",
    "    df = df.droplevel(0, axis=1)\n",
    "    print(df.head())\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\n",
    "        'operating': 'Added (MW)', \n",
    "        'Start year': 'Year'\n",
    "    })\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing countries\n",
    "def add_missing_countries(df):\n",
    "    # add any missing countries, to make sure that all countries in gcpt_country_list are in gcpt_map\n",
    "    # missing_countries = [x for x in gcpt_country_list if x not in gcpt_add['Country'].tolist()]\n",
    "    missing_countries = [x for x in gogpt_country_list if x not in gogpt_add['Country'].tolist()]\n",
    "    print(missing_countries)\n",
    "\n",
    "    print(f\"Show any countries missing (which will be added below): {missing_countries}\")\n",
    "    \n",
    "    for year in range(int(gogpt_add['Year'].min()), \n",
    "        int(max_year)+1):\n",
    "\n",
    "        new_df = pd.DataFrame.from_dict({\n",
    "                'Country': missing_countries,\n",
    "                'Year': year,\n",
    "                'Added (MW)': [float(0)]*len(missing_countries),\n",
    "                # 'Status': 'operating',\n",
    "            }, orient='columns')\n",
    "        print(f'this is new df: {new_df}')\n",
    "        df = pd.concat([df, new_df], sort=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_in_missing_years(df):\n",
    "\n",
    "    for country_sel in gogpt_country_list:\n",
    "        for year in range(int(gogpt_add['Year'].min()), \n",
    "            int(max_year)+1):\n",
    "\n",
    "            df_sel = df[(df['Country']==country_sel) & (df['Year']==year)]\n",
    "            if len(df_sel) == 0:\n",
    "                new_df = pd.DataFrame.from_dict({\n",
    "                        'Country': country_sel,\n",
    "                        'Year': year,\n",
    "                        'Added (MW)': [float(0)],\n",
    "                    }, orient='columns')\n",
    "                df = pd.concat([df, new_df], sort=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then groupby capacities by year and country\n",
    "def add_calculate_global_totals(df):\n",
    "    gogpt_add_all = df.groupby(['Year'])[['Added (MW)']].sum().reset_index()\n",
    "    gogpt_add_all.insert(0, 'Country', 'all')\n",
    "    df = pd.concat([gogpt_add_all, df], sort=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gogpt_add = add_unstack(gogpt_add)\n",
    "gogpt_add = add_missing_countries(gogpt_add)\n",
    "gogpt_add = add_calculate_global_totals(gogpt_add)\n",
    "gogpt_add = fill_in_missing_years(gogpt_add)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test against excel file \n",
    "gogpt_add[(gogpt_add['Country']=='all')&(gogpt_add['Year']==2010)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to various sheets of one Excel file by creating ExcelWriter object\n",
    "template_name = gogpt_dash_file_h1_2023.split('.xlsx')[0]\n",
    "save_timestamp = time.strftime('%Y-%m-%d_%H%M', time.localtime())\n",
    "file_name = f'{template_name} - processed for Dash {save_timestamp}.xlsx'\n",
    "with pd.ExcelWriter(gogpt_dash_path + file_name) as writer:\n",
    "    gogpt_map.to_excel(writer, sheet_name='map', index=False)  \n",
    "    gogpt_status.to_excel(writer, sheet_name='status', index=False)\n",
    "    gogpt_age.to_excel(writer, sheet_name='age', index=False)\n",
    "    gogpt_add.to_excel(writer, sheet_name='additions', index=False)\n",
    "    print(f\"Saved to file: {file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dashboardenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
